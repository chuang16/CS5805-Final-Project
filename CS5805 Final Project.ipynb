{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c246a734",
   "metadata": {
    "id": "c246a734"
   },
   "source": [
    "# CS5805 Final Project: YOLO Implementation on Facial Detection/Pixelization\n",
    "### Corey Huang, Allison Deaton, Ken Lin, Rebecca Yeung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377c2a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a377c2a8",
    "outputId": "5808a4c4-a7c0-491d-ca01-000d901cb8a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb15f68",
   "metadata": {
    "id": "6cb15f68"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db7fce",
   "metadata": {
    "id": "c1db7fce"
   },
   "outputs": [],
   "source": [
    "# Parse annotation files\n",
    "def parse_annotations(annotation_file, images_dir):\n",
    "    data = []\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        # Read image path\n",
    "        relative_image_path = lines[i].strip()\n",
    "        image_path = os.path.join(images_dir, relative_image_path)\n",
    "        i += 1\n",
    "        # Skip if image doesn't exist\n",
    "        if not os.path.exists(image_path):\n",
    "            while i < len(lines) and lines[i].strip().isdigit():\n",
    "                i += 1\n",
    "            continue\n",
    "        # Number of faces in image\n",
    "        num_faces = int(lines[i].strip())\n",
    "        i += 1\n",
    "        # Read bounding boxes\n",
    "        bounding_boxes = []\n",
    "        for _ in range(num_faces):\n",
    "            if i >= len(lines):\n",
    "                break\n",
    "            # Get position of bounding box\n",
    "            bounding_box = list(map(int, lines[i].strip().split()[:4]))\n",
    "            x_min, y_min, width, height = bounding_box\n",
    "            x_max = x_min + width\n",
    "            y_max = y_min + height\n",
    "            bounding_boxes.append([x_min, y_min, x_max, y_max])\n",
    "            i += 1\n",
    "        # Add image path and bounding boxes\n",
    "        data.append({'image_path': image_path, 'bounding_boxes': bounding_boxes})\n",
    "    return data\n",
    "\n",
    "# Dataset directories\n",
    "train_images_dir = \"data/WIDER_train\"\n",
    "val_images_dir = \"data/WIDER_val\"\n",
    "test_images_dir = \"data/WIDER_test\"\n",
    "\n",
    "# Annotation files\n",
    "train_annotation_file = \"data/wider_face_split/wider_face_train_bbx_gt.txt\"\n",
    "val_annotation_file = \"data/wider_face_split/wider_face_val_bbx_gt.txt\"\n",
    "\n",
    "# Load annotations for training and validation datasets\n",
    "train_data = parse_annotations(train_annotation_file, train_images_dir)\n",
    "val_data = parse_annotations(val_annotation_file, val_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ff14f",
   "metadata": {
    "id": "348ff14f"
   },
   "outputs": [],
   "source": [
    "# Format data for YOLO using random samples\n",
    "def sampled_yolo(data, output_dir, sample_size):\n",
    "    # Clear directory of previous data\n",
    "    if os.path.exists(output_dir):\n",
    "        for filename in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "    # Make directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    # Random sample of data\n",
    "    sampled_data = random.sample(data, min(sample_size, len(data)))\n",
    "    for item in sampled_data:\n",
    "        image_path = item['image_path']\n",
    "        image_name = os.path.basename(image_path)\n",
    "        annotation_name = os.path.splitext(image_name)[0] + \".txt\"\n",
    "        # Copy image to output directory\n",
    "        shutil.copy(image_path, os.path.join(output_dir, image_name))\n",
    "        # Create YOLO annotations\n",
    "        yolo_annotations = []\n",
    "        try:\n",
    "            import cv2\n",
    "            image = cv2.imread(image_path)\n",
    "            height, width, _ = image.shape\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        for (x_min, y_min, x_max, y_max) in item['bounding_boxes']:\n",
    "            x_center = (x_min + x_max) / 2 / width\n",
    "            y_center = (y_min + y_max) / 2 / height\n",
    "            box_width = (x_max - x_min) / width\n",
    "            box_height = (y_max - y_min) / height\n",
    "            yolo_annotations.append(f\"0 {x_center} {y_center} {box_width} {box_height}\")\n",
    "        # Save annotations to file\n",
    "        with open(os.path.join(output_dir, annotation_name), 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "# Output directories for sampled datasets\n",
    "sampled_train_dir = \"data/sampled_train\"\n",
    "sampled_val_dir = \"data/sampled_val\"\n",
    "sampled_test_dir = \"data/sampled_test\"\n",
    "\n",
    "# Number of images for sampling (train ~70%, val ~15%, test ~15%)\n",
    "train_sample_size = 500\n",
    "val_sample_size = 100\n",
    "test_sample_size = 100\n",
    "\n",
    "# Get sample datasets\n",
    "sampled_yolo(train_data, sampled_train_dir, train_sample_size)\n",
    "sampled_yolo(val_data, sampled_val_dir, val_sample_size)\n",
    "sampled_yolo(val_data, sampled_test_dir, test_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448929a",
   "metadata": {
    "id": "2448929a"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7582df0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7582df0",
    "outputId": "2c1e4f54-235e-4d5b-d47b-483c5194bbce"
   },
   "outputs": [],
   "source": [
    "# Check if CUDA is available (GPU or CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.to(device)\n",
    "\n",
    "# Path to dataset YAML file (must change path inside file to your own)\n",
    "data_yaml = 'data.yaml'\n",
    "\n",
    "# Train model\n",
    "model.train(\n",
    "    data=data_yaml,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    workers=4,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Evaluate model with validation data\n",
    "metrics = model.val()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find results data\n",
    "def find_results(base_dir):\n",
    "    # List of results files\n",
    "    results_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if 'results.csv' in files:\n",
    "            results_file = os.path.join(root, 'results.csv')\n",
    "            results_files.append(results_file)\n",
    "    if results_files:\n",
    "        # Sort by latest results files\n",
    "        results_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "        return results_files[0]\n",
    "    return None\n",
    "\n",
    "# Load results file\n",
    "results_dir = find_results(\"runs/detect\")\n",
    "results_data = pd.read_csv(results_dir)\n",
    "\n",
    "# Extract relevant data\n",
    "epochs = results_data['epoch']\n",
    "map50_95 = results_data['metrics/mAP50-95(B)']\n",
    "\n",
    "# Plot mAP@50-95 over epochs\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(epochs, map50_95, marker='o', linestyle='-', color='b', label='mAP@50-95')\n",
    "plt.title('Performance Over Training Epochs', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('mAP@50-95', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VgYuAFJsocKX",
   "metadata": {
    "id": "VgYuAFJsocKX"
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gkbrCTUooTzN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkbrCTUooTzN",
    "outputId": "f7d3040c-5752-4106-f8f6-763a3e030ea9"
   },
   "outputs": [],
   "source": [
    "# Run model on test data\n",
    "results = model.predict(\n",
    "    source=sampled_test_dir,\n",
    "    conf=0.5,\n",
    "    imgsz=640,\n",
    "    device=device,\n",
    "    save=True,\n",
    "    save_txt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ChBrBoE_p6Ux",
   "metadata": {
    "id": "ChBrBoE_p6Ux"
   },
   "source": [
    "## Pixelate Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hfnHVJIhqJNo",
   "metadata": {
    "id": "hfnHVJIhqJNo"
   },
   "outputs": [],
   "source": [
    "# Pixelate faces for image\n",
    "def pixelate_face(image_path, bounding_boxes):\n",
    "    image = cv2.imread(image_path)\n",
    "    for (x_min, y_min, x_max, y_max) in bounding_boxes:\n",
    "        # Extract face region in bounding box\n",
    "        face = image[y_min:y_max, x_min:x_max]\n",
    "        # Resize region to 16x16 pixels using linear interpolation\n",
    "        face = cv2.resize(face, (16, 16), interpolation=cv2.INTER_LINEAR)\n",
    "        # Resize region back to bounding box size using nearest-neighbor interpolation\n",
    "        face = cv2.resize(face, (x_max - x_min, y_max - y_min), interpolation=cv2.INTER_NEAREST)\n",
    "        # Replace original image with pixelated face\n",
    "        image[y_min:y_max, x_min:x_max] = face\n",
    "    return image\n",
    "\n",
    "# Apply pixelizations to images\n",
    "def pixelization(image_dir, results_dir, output_dir):\n",
    "    # Clear directory of previous data\n",
    "    if os.path.exists(output_dir):\n",
    "        for filename in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "    # Make directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for file in os.listdir(results_dir):\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "        image_path = os.path.join(image_dir, file.replace('.txt', '.jpg'))\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        bounding_boxes = []\n",
    "        with open(os.path.join(results_dir, file), 'r') as f:\n",
    "            for line in f:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "                # Load image to calculate dimensions\n",
    "                image = cv2.imread(image_path)\n",
    "                img_height, img_width = image.shape[:2]\n",
    "                x_min = int((x_center - width / 2) * img_width)\n",
    "                y_min = int((y_center - height / 2) * img_height)\n",
    "                x_max = int((x_center + width / 2) * img_width)\n",
    "                y_max = int((y_center + height / 2) * img_height)\n",
    "                bounding_boxes.append((x_min, y_min, x_max, y_max))\n",
    "        # Pixelate faces in image\n",
    "        pixelated_image = pixelate_face(image_path, bounding_boxes)\n",
    "        # Save pixelated image to output directory\n",
    "        output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "        cv2.imwrite(output_path, pixelated_image)\n",
    "\n",
    "# Find directory for test data labels\n",
    "def find_labels_dir(base_dir):\n",
    "    # List of label directories\n",
    "    labels_dirs = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if 'labels' in dirs:\n",
    "            labels_path = os.path.join(root, 'labels')\n",
    "            labels_dirs.append(labels_path)\n",
    "    if labels_dirs:\n",
    "        # Sort by latest label directory\n",
    "        labels_dirs.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "        return labels_dirs[0]\n",
    "    return None\n",
    "\n",
    "labels_dir = find_labels_dir(\"runs/detect\")\n",
    "pixelated_images_dir = \"pixelated_images\"\n",
    "\n",
    "pixelation(sampled_test_dir, labels_dir, pixelated_images_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
